{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your dataset folder path on Google Drive\n",
        "dataset_path = '/content/drive/My Drive/liver cancer dataset'\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,  # Rescale pixel values to [0, 1]\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split=0.2  # Split data into training and validation\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(200, 200),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(200, 200),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Create ResNet-50 model with transfer learning\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model checkpoint for saving the best weights\n",
        "model_checkpoint = ModelCheckpoint('liver_cancer_detection.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, validation_data=valid_generator, epochs=15, callbacks=[model_checkpoint])\n",
        "#show matrix\n",
        "# Load the best model weights\n",
        "model.load_weights('liver_cancer_detection.h5')\n",
        "\n",
        "# Predict labels on the validation data\n",
        "valid_generator.reset()  # Reset the generator to the beginning\n",
        "y_pred = model.predict(valid_generator, steps=len(valid_generator), verbose=1)\n",
        "y_pred = np.round(y_pred)  # Round the predictions to 0 or 1\n",
        "\n",
        "# Get the true labels\n",
        "y_true = valid_generator.classes\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n",
        "\n",
        "# You can also print a classification report for additional metrics\n",
        "classification_rep = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'])\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "\n",
        "# Save the final model\n",
        "model.save('liver_cancer_detection_final.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qxd5tPGKtSz",
        "outputId": "6fbdad27-a2e4-43c3-fb72-2810f44cb6ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 69 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.0930 - accuracy: 0.4638\n",
            "Epoch 1: val_loss improved from inf to 0.89205, saving model to liver_cancer_detection.h5\n",
            "3/3 [==============================] - 46s 19s/step - loss: 1.0930 - accuracy: 0.4638 - val_loss: 0.8921 - val_accuracy: 0.6250\n",
            "Epoch 2/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.2885 - accuracy: 0.5942\n",
            "Epoch 2: val_loss did not improve from 0.89205\n",
            "3/3 [==============================] - 14s 4s/step - loss: 1.2885 - accuracy: 0.5942 - val_loss: 1.2716 - val_accuracy: 0.6250\n",
            "Epoch 3/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.9139 - accuracy: 0.5942\n",
            "Epoch 3: val_loss improved from 0.89205 to 0.75386, saving model to liver_cancer_detection.h5\n",
            "3/3 [==============================] - 16s 8s/step - loss: 0.9139 - accuracy: 0.5942 - val_loss: 0.7539 - val_accuracy: 0.3750\n",
            "Epoch 4/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8197 - accuracy: 0.4058\n",
            "Epoch 4: val_loss did not improve from 0.75386\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.8197 - accuracy: 0.4058 - val_loss: 0.8410 - val_accuracy: 0.3750\n",
            "Epoch 5/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.7850 - accuracy: 0.4203\n",
            "Epoch 5: val_loss improved from 0.75386 to 0.65418, saving model to liver_cancer_detection.h5\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.7850 - accuracy: 0.4203 - val_loss: 0.6542 - val_accuracy: 0.6250\n",
            "Epoch 6/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.5942\n",
            "Epoch 6: val_loss did not improve from 0.65418\n",
            "3/3 [==============================] - 14s 3s/step - loss: 0.6777 - accuracy: 0.5942 - val_loss: 0.6636 - val_accuracy: 0.6250\n",
            "Epoch 7/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.6377\n",
            "Epoch 7: val_loss did not improve from 0.65418\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.6600 - accuracy: 0.6377 - val_loss: 0.6800 - val_accuracy: 0.6250\n",
            "Epoch 8/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.6377\n",
            "Epoch 8: val_loss did not improve from 0.65418\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.6660 - accuracy: 0.6377 - val_loss: 0.7316 - val_accuracy: 0.3750\n",
            "Epoch 9/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.7139 - accuracy: 0.4058\n",
            "Epoch 9: val_loss did not improve from 0.65418\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.7139 - accuracy: 0.4058 - val_loss: 0.6987 - val_accuracy: 0.4375\n",
            "Epoch 10/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6784 - accuracy: 0.5942\n",
            "Epoch 10: val_loss improved from 0.65418 to 0.62484, saving model to liver_cancer_detection.h5\n",
            "3/3 [==============================] - 17s 5s/step - loss: 0.6784 - accuracy: 0.5942 - val_loss: 0.6248 - val_accuracy: 0.6875\n",
            "Epoch 11/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.6377\n",
            "Epoch 11: val_loss did not improve from 0.62484\n",
            "3/3 [==============================] - 15s 7s/step - loss: 0.6530 - accuracy: 0.6377 - val_loss: 0.6350 - val_accuracy: 0.6250\n",
            "Epoch 12/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.5942\n",
            "Epoch 12: val_loss did not improve from 0.62484\n",
            "3/3 [==============================] - 14s 6s/step - loss: 0.6622 - accuracy: 0.5942 - val_loss: 0.6350 - val_accuracy: 0.6250\n",
            "Epoch 13/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6476 - accuracy: 0.6377\n",
            "Epoch 13: val_loss did not improve from 0.62484\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.6476 - accuracy: 0.6377 - val_loss: 0.6579 - val_accuracy: 0.6250\n",
            "Epoch 14/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.6667\n",
            "Epoch 14: val_loss did not improve from 0.62484\n",
            "3/3 [==============================] - 15s 7s/step - loss: 0.6651 - accuracy: 0.6667 - val_loss: 0.6502 - val_accuracy: 0.6250\n",
            "Epoch 15/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.6377\n",
            "Epoch 15: val_loss did not improve from 0.62484\n",
            "3/3 [==============================] - 14s 4s/step - loss: 0.6657 - accuracy: 0.6377 - val_loss: 0.6705 - val_accuracy: 0.6250\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Confusion Matrix:\n",
            "[[0 6]\n",
            " [1 9]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.00      0.00      0.00         6\n",
            "     Class 1       0.60      0.90      0.72        10\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.30      0.45      0.36        16\n",
            "weighted avg       0.38      0.56      0.45        16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('liver_cancer_detection_final.h5')\n",
        "# Test with a sample image\n",
        "test_image_path = '/content/drive/My Drive/image test/n (1).bmp'  # Provide the path to your test image\n",
        "\n",
        "prediction = predict(test_image_path)\n",
        "\n",
        "if prediction > 0.5:\n",
        "    print(\"The model predicts that this image indicates liver cancer.\")\n",
        "else:\n",
        "    print(\"The model predicts that this image does not indicate liver cancer.\")\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(200, 200))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img /= 255.0  # Rescale pixel values to [0, 1]\n",
        "    return img\n",
        "def predict(image_path):\n",
        "    processed_image = preprocess_image(image_path)\n",
        "    prediction = model.predict(processed_image)\n",
        "    return prediction[0][0]  # Get the probability of having liver cancer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7ccb29-0774-4296-a7d6-aa707d824a45",
        "id": "wGF8EXqmQceF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "The model predicts that this image does not indicate liver cancer.\n"
          ]
        }
      ]
    }
  ]
}